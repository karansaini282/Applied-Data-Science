{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for network data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder is a non-linear dimensionality reduction tool (deep representation learning). It is an artificial neural network, or actually two neural networks being trained simultaneously:  \n",
    "- first half of the layers or first network encodes the input high-dimensional data into lower-dimensional representation space, gradually reducing dimensionality from layer to layer;  \n",
    "- second half transforms it back from the low-dimensional encoded representation feature space to the original dimensionality.\n",
    "\n",
    "The architectures of the two parts are usually symmetric as could be seen on the figure below\n",
    "\n",
    "<img src=\"autoencoder.png\">\n",
    "\n",
    "Two useful blogs for getting started:  \n",
    "\n",
    "https://ramhiser.com/post/2018-05-14-autoencoders-with-keras/\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/autoencoder-keras-tutorial  \n",
    "\n",
    "https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798\n",
    "\n",
    "(credits for the figure to the third one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras import regularizers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of the below is to read a temporal network (each row is a time-slice, columns are edge weights) and run autoencoder to convert it to a smaller space of representative feature timelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(filename,X):\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(X,outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    infile = open(filename,'rb')\n",
    "    X=pickle.load(infile)\n",
    "    infile.close()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=load('Taipeiexchange1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=X[400:,0:100]; x_train=X[0:400,0:100]; #split the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression factor: 6.66666666667\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 25)                400       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 40)                1040      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 60)                2460      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 80)                4880      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               8100      \n",
      "=================================================================\n",
      "Total params: 33,675\n",
      "Trainable params: 33,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#design autoencoder\n",
    "input_dim = x_train.shape[1]\n",
    "#encoding_dim = [50,15,5,2] #sizes of the layers\n",
    "#encoding_dim = [30,10,3] #sizes of the layers\n",
    "encoding_dim = [80,60,40,25,15] #sizes of the layers\n",
    "#encoding_dim = [50,25,12] #sizes of the layers\n",
    "\n",
    "compression_factor = float(input_dim) / encoding_dim[-1]\n",
    "print(\"Compression factor: %s\" % compression_factor)\n",
    "\n",
    "#define autoencoder architecture\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(\n",
    "    Dense(encoding_dim[0], input_shape=(input_dim,), activation='relu')\n",
    ")\n",
    "\n",
    "for l in range(1,len(encoding_dim)):\n",
    "    autoencoder.add(\n",
    "         Dense(encoding_dim[l], input_shape=(encoding_dim[l-1],), activation='relu')\n",
    "    )\n",
    "    \n",
    "for l in range(len(encoding_dim)-1,0,-1):\n",
    "    autoencoder.add(\n",
    "         Dense(encoding_dim[l-1], input_shape=(encoding_dim[l],), activation='relu')\n",
    "     )\n",
    "\n",
    "autoencoder.add(\n",
    "    Dense(input_dim, input_shape=(encoding_dim[0],), activation='sigmoid')\n",
    ")\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 269 samples\n",
      "Epoch 1/400\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.6921 - val_loss: 0.6893\n",
      "Epoch 2/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.6834 - val_loss: 0.6708\n",
      "Epoch 3/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.6538 - val_loss: 0.6338\n",
      "Epoch 4/400\n",
      "400/400 [==============================] - 0s 126us/step - loss: 0.6249 - val_loss: 0.6083\n",
      "Epoch 5/400\n",
      "400/400 [==============================] - 0s 126us/step - loss: 0.6064 - val_loss: 0.5964\n",
      "Epoch 6/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5966 - val_loss: 0.5870\n",
      "Epoch 7/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.5872 - val_loss: 0.5806\n",
      "Epoch 8/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5820 - val_loss: 0.5767\n",
      "Epoch 9/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5789 - val_loss: 0.5749\n",
      "Epoch 10/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5777 - val_loss: 0.5743\n",
      "Epoch 11/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.5770 - val_loss: 0.5739\n",
      "Epoch 12/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5766 - val_loss: 0.5733\n",
      "Epoch 13/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5762 - val_loss: 0.5732\n",
      "Epoch 14/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5760 - val_loss: 0.5730\n",
      "Epoch 15/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5757 - val_loss: 0.5727\n",
      "Epoch 16/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5755 - val_loss: 0.5728\n",
      "Epoch 17/400\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.5753 - val_loss: 0.5721\n",
      "Epoch 18/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5748 - val_loss: 0.5717\n",
      "Epoch 19/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5745 - val_loss: 0.5712\n",
      "Epoch 20/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.5742 - val_loss: 0.5709\n",
      "Epoch 21/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5738 - val_loss: 0.5703\n",
      "Epoch 22/400\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.5734 - val_loss: 0.5699\n",
      "Epoch 23/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5729 - val_loss: 0.5694\n",
      "Epoch 24/400\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.5725 - val_loss: 0.5691\n",
      "Epoch 25/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5721 - val_loss: 0.5686\n",
      "Epoch 26/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.5719 - val_loss: 0.5682\n",
      "Epoch 27/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5716 - val_loss: 0.5680\n",
      "Epoch 28/400\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.5713 - val_loss: 0.5676\n",
      "Epoch 29/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5712 - val_loss: 0.5681\n",
      "Epoch 30/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5711 - val_loss: 0.5677\n",
      "Epoch 31/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5711 - val_loss: 0.5674\n",
      "Epoch 32/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5708 - val_loss: 0.5673\n",
      "Epoch 33/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5707 - val_loss: 0.5670\n",
      "Epoch 34/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5706 - val_loss: 0.5673\n",
      "Epoch 35/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5705 - val_loss: 0.5670\n",
      "Epoch 36/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5703 - val_loss: 0.5669\n",
      "Epoch 37/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5702 - val_loss: 0.5669\n",
      "Epoch 38/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5702 - val_loss: 0.5668\n",
      "Epoch 39/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5701 - val_loss: 0.5667\n",
      "Epoch 40/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5700 - val_loss: 0.5665\n",
      "Epoch 41/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5700 - val_loss: 0.5665\n",
      "Epoch 42/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5701 - val_loss: 0.5665\n",
      "Epoch 43/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5700 - val_loss: 0.5664\n",
      "Epoch 44/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5698 - val_loss: 0.5666\n",
      "Epoch 45/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5697 - val_loss: 0.5663\n",
      "Epoch 46/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5697 - val_loss: 0.5663\n",
      "Epoch 47/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5696 - val_loss: 0.5663\n",
      "Epoch 48/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5697 - val_loss: 0.5665\n",
      "Epoch 49/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5696 - val_loss: 0.5661\n",
      "Epoch 50/400\n",
      "400/400 [==============================] - 0s 261us/step - loss: 0.5696 - val_loss: 0.5662\n",
      "Epoch 51/400\n",
      "400/400 [==============================] - 0s 153us/step - loss: 0.5695 - val_loss: 0.5663\n",
      "Epoch 52/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5695 - val_loss: 0.5661\n",
      "Epoch 53/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5694 - val_loss: 0.5661\n",
      "Epoch 54/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5694 - val_loss: 0.5661\n",
      "Epoch 55/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5694 - val_loss: 0.5661\n",
      "Epoch 56/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5693 - val_loss: 0.5660\n",
      "Epoch 57/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5693 - val_loss: 0.5661\n",
      "Epoch 58/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5692 - val_loss: 0.5661\n",
      "Epoch 59/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5692 - val_loss: 0.5659\n",
      "Epoch 60/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5692 - val_loss: 0.5661\n",
      "Epoch 61/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5691 - val_loss: 0.5659\n",
      "Epoch 62/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5691 - val_loss: 0.5660\n",
      "Epoch 63/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5691 - val_loss: 0.5659\n",
      "Epoch 64/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5691 - val_loss: 0.5660\n",
      "Epoch 65/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5690 - val_loss: 0.5660\n",
      "Epoch 66/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5690 - val_loss: 0.5658\n",
      "Epoch 67/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5690 - val_loss: 0.5658\n",
      "Epoch 68/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5689 - val_loss: 0.5657\n",
      "Epoch 69/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5688 - val_loss: 0.5657\n",
      "Epoch 70/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5688 - val_loss: 0.5657\n",
      "Epoch 71/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5688 - val_loss: 0.5656\n",
      "Epoch 72/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5687 - val_loss: 0.5656\n",
      "Epoch 73/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5687 - val_loss: 0.5655\n",
      "Epoch 74/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5687 - val_loss: 0.5656\n",
      "Epoch 75/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5687 - val_loss: 0.5656\n",
      "Epoch 76/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5687 - val_loss: 0.5655\n",
      "Epoch 77/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5686 - val_loss: 0.5654\n",
      "Epoch 78/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5685 - val_loss: 0.5655\n",
      "Epoch 79/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5685 - val_loss: 0.5655\n",
      "Epoch 80/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5685 - val_loss: 0.5655\n",
      "Epoch 81/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5684 - val_loss: 0.5653\n",
      "Epoch 82/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5684 - val_loss: 0.5654\n",
      "Epoch 83/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5684 - val_loss: 0.5654\n",
      "Epoch 84/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5683 - val_loss: 0.5653\n",
      "Epoch 85/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5683 - val_loss: 0.5653\n",
      "Epoch 86/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5682 - val_loss: 0.5652\n",
      "Epoch 87/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5682 - val_loss: 0.5653\n",
      "Epoch 88/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5682 - val_loss: 0.5653\n",
      "Epoch 89/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5682 - val_loss: 0.5651\n",
      "Epoch 90/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5681 - val_loss: 0.5654\n",
      "Epoch 91/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5681 - val_loss: 0.5650\n",
      "Epoch 92/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5680 - val_loss: 0.5651\n",
      "Epoch 93/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5679 - val_loss: 0.5651\n",
      "Epoch 94/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5679 - val_loss: 0.5650\n",
      "Epoch 95/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5679 - val_loss: 0.5651\n",
      "Epoch 96/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5679 - val_loss: 0.5651\n",
      "Epoch 97/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5679 - val_loss: 0.5649\n",
      "Epoch 98/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5678 - val_loss: 0.5649\n",
      "Epoch 99/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5679 - val_loss: 0.5650\n",
      "Epoch 100/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5678 - val_loss: 0.5648\n",
      "Epoch 101/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5677 - val_loss: 0.5648\n",
      "Epoch 102/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5677 - val_loss: 0.5646\n",
      "Epoch 103/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5676 - val_loss: 0.5647\n",
      "Epoch 104/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5676 - val_loss: 0.5649\n",
      "Epoch 105/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5676 - val_loss: 0.5646\n",
      "Epoch 106/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5676 - val_loss: 0.5648\n",
      "Epoch 107/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5675 - val_loss: 0.5648\n",
      "Epoch 108/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5676 - val_loss: 0.5647\n",
      "Epoch 109/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5674 - val_loss: 0.5646\n",
      "Epoch 110/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5675 - val_loss: 0.5646\n",
      "Epoch 111/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5674 - val_loss: 0.5645\n",
      "Epoch 112/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5673 - val_loss: 0.5646\n",
      "Epoch 113/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5673 - val_loss: 0.5646\n",
      "Epoch 114/400\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.5673 - val_loss: 0.5646\n",
      "Epoch 115/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5672 - val_loss: 0.5644\n",
      "Epoch 116/400\n",
      "400/400 [==============================] - 0s 128us/step - loss: 0.5671 - val_loss: 0.5645\n",
      "Epoch 117/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5671 - val_loss: 0.5645\n",
      "Epoch 118/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5671 - val_loss: 0.5643\n",
      "Epoch 119/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5670 - val_loss: 0.5644\n",
      "Epoch 120/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5670 - val_loss: 0.5644\n",
      "Epoch 121/400\n",
      "400/400 [==============================] - 0s 154us/step - loss: 0.5670 - val_loss: 0.5643\n",
      "Epoch 122/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5670 - val_loss: 0.5642\n",
      "Epoch 123/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5669 - val_loss: 0.5643\n",
      "Epoch 124/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5668 - val_loss: 0.5642\n",
      "Epoch 125/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.5668 - val_loss: 0.5642\n",
      "Epoch 126/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5669 - val_loss: 0.5641\n",
      "Epoch 127/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5668 - val_loss: 0.5643\n",
      "Epoch 128/400\n",
      "400/400 [==============================] - 0s 127us/step - loss: 0.5667 - val_loss: 0.5641\n",
      "Epoch 129/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5667 - val_loss: 0.5640\n",
      "Epoch 130/400\n",
      "400/400 [==============================] - 0s 130us/step - loss: 0.5667 - val_loss: 0.5642\n",
      "Epoch 131/400\n",
      "400/400 [==============================] - 0s 129us/step - loss: 0.5667 - val_loss: 0.5642\n",
      "Epoch 132/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5667 - val_loss: 0.5643\n",
      "Epoch 133/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5667 - val_loss: 0.5643\n",
      "Epoch 134/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5667 - val_loss: 0.5643\n",
      "Epoch 135/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5666 - val_loss: 0.5641\n",
      "Epoch 136/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5666 - val_loss: 0.5641\n",
      "Epoch 137/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5665 - val_loss: 0.5641\n",
      "Epoch 138/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5665 - val_loss: 0.5641\n",
      "Epoch 139/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5665 - val_loss: 0.5641\n",
      "Epoch 140/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5664 - val_loss: 0.5639\n",
      "Epoch 141/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5664 - val_loss: 0.5640\n",
      "Epoch 142/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5664 - val_loss: 0.5642\n",
      "Epoch 143/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5664 - val_loss: 0.5639\n",
      "Epoch 144/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5664 - val_loss: 0.5641\n",
      "Epoch 145/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5665 - val_loss: 0.5641\n",
      "Epoch 146/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5665 - val_loss: 0.5643\n",
      "Epoch 147/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5666 - val_loss: 0.5642\n",
      "Epoch 148/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5665 - val_loss: 0.5640\n",
      "Epoch 149/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5664 - val_loss: 0.5643\n",
      "Epoch 150/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5664 - val_loss: 0.5639\n",
      "Epoch 151/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5664 - val_loss: 0.5640\n",
      "Epoch 152/400\n",
      "400/400 [==============================] - 0s 146us/step - loss: 0.5664 - val_loss: 0.5640\n",
      "Epoch 153/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5663 - val_loss: 0.5639\n",
      "Epoch 154/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5663 - val_loss: 0.5642\n",
      "Epoch 155/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5663 - val_loss: 0.5639\n",
      "Epoch 156/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5662 - val_loss: 0.5640\n",
      "Epoch 157/400\n",
      "400/400 [==============================] - 0s 145us/step - loss: 0.5662 - val_loss: 0.5642\n",
      "Epoch 158/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5663 - val_loss: 0.5639\n",
      "Epoch 159/400\n",
      "400/400 [==============================] - 0s 146us/step - loss: 0.5662 - val_loss: 0.5640\n",
      "Epoch 160/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5662 - val_loss: 0.5642\n",
      "Epoch 161/400\n",
      "400/400 [==============================] - 0s 145us/step - loss: 0.5662 - val_loss: 0.5640\n",
      "Epoch 162/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5662 - val_loss: 0.5638\n",
      "Epoch 163/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5662 - val_loss: 0.5638\n",
      "Epoch 164/400\n",
      "400/400 [==============================] - 0s 145us/step - loss: 0.5661 - val_loss: 0.5637\n",
      "Epoch 165/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5661 - val_loss: 0.5638\n",
      "Epoch 166/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5661 - val_loss: 0.5639\n",
      "Epoch 167/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5661 - val_loss: 0.5637\n",
      "Epoch 168/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5661 - val_loss: 0.5636\n",
      "Epoch 169/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5661 - val_loss: 0.5639\n",
      "Epoch 170/400\n",
      "400/400 [==============================] - 0s 146us/step - loss: 0.5661 - val_loss: 0.5639\n",
      "Epoch 171/400\n",
      "400/400 [==============================] - 0s 149us/step - loss: 0.5660 - val_loss: 0.5639\n",
      "Epoch 172/400\n",
      "400/400 [==============================] - 0s 146us/step - loss: 0.5660 - val_loss: 0.5637\n",
      "Epoch 173/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5660 - val_loss: 0.5638\n",
      "Epoch 174/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5660 - val_loss: 0.5637\n",
      "Epoch 175/400\n",
      "400/400 [==============================] - 0s 152us/step - loss: 0.5659 - val_loss: 0.5637\n",
      "Epoch 176/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5659 - val_loss: 0.5639\n",
      "Epoch 177/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5659 - val_loss: 0.5635\n",
      "Epoch 178/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5659 - val_loss: 0.5637\n",
      "Epoch 179/400\n",
      "400/400 [==============================] - 0s 147us/step - loss: 0.5658 - val_loss: 0.5633\n",
      "Epoch 180/400\n",
      "400/400 [==============================] - 0s 145us/step - loss: 0.5658 - val_loss: 0.5636\n",
      "Epoch 181/400\n",
      "400/400 [==============================] - 0s 147us/step - loss: 0.5658 - val_loss: 0.5636\n",
      "Epoch 182/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5658 - val_loss: 0.5634\n",
      "Epoch 183/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5657 - val_loss: 0.5636\n",
      "Epoch 184/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5657 - val_loss: 0.5634\n",
      "Epoch 185/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5656 - val_loss: 0.5632\n",
      "Epoch 186/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5656 - val_loss: 0.5633\n",
      "Epoch 187/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5656 - val_loss: 0.5634\n",
      "Epoch 188/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5655 - val_loss: 0.5634\n",
      "Epoch 189/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5655 - val_loss: 0.5632\n",
      "Epoch 190/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5655 - val_loss: 0.5633\n",
      "Epoch 191/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5655 - val_loss: 0.5634\n",
      "Epoch 192/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5655 - val_loss: 0.5634\n",
      "Epoch 193/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5655 - val_loss: 0.5630\n",
      "Epoch 194/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5655 - val_loss: 0.5633\n",
      "Epoch 195/400\n",
      "400/400 [==============================] - 0s 147us/step - loss: 0.5654 - val_loss: 0.5632\n",
      "Epoch 196/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5654 - val_loss: 0.5631\n",
      "Epoch 197/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5653 - val_loss: 0.5633\n",
      "Epoch 198/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5653 - val_loss: 0.5630\n",
      "Epoch 199/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5653 - val_loss: 0.5632\n",
      "Epoch 200/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5653 - val_loss: 0.5631\n",
      "Epoch 201/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5652 - val_loss: 0.5631\n",
      "Epoch 202/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5652 - val_loss: 0.5632\n",
      "Epoch 203/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5652 - val_loss: 0.5630\n",
      "Epoch 204/400\n",
      "400/400 [==============================] - 0s 145us/step - loss: 0.5652 - val_loss: 0.5632\n",
      "Epoch 205/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5652 - val_loss: 0.5633\n",
      "Epoch 206/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5652 - val_loss: 0.5631\n",
      "Epoch 207/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5652 - val_loss: 0.5631\n",
      "Epoch 208/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5651 - val_loss: 0.5631\n",
      "Epoch 209/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5651 - val_loss: 0.5632\n",
      "Epoch 210/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5651 - val_loss: 0.5629\n",
      "Epoch 211/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5651 - val_loss: 0.5631\n",
      "Epoch 212/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5651 - val_loss: 0.5633\n",
      "Epoch 213/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5651 - val_loss: 0.5631\n",
      "Epoch 214/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5650 - val_loss: 0.5631\n",
      "Epoch 215/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5650 - val_loss: 0.5633\n",
      "Epoch 216/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5650 - val_loss: 0.5629\n",
      "Epoch 217/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5650 - val_loss: 0.5630\n",
      "Epoch 218/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5651 - val_loss: 0.5634\n",
      "Epoch 219/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5651 - val_loss: 0.5631\n",
      "Epoch 220/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5650 - val_loss: 0.5631\n",
      "Epoch 221/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5650 - val_loss: 0.5633\n",
      "Epoch 222/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5650 - val_loss: 0.5632\n",
      "Epoch 223/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5650 - val_loss: 0.5631\n",
      "Epoch 224/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5649 - val_loss: 0.5631\n",
      "Epoch 225/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5649 - val_loss: 0.5630\n",
      "Epoch 226/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5649 - val_loss: 0.5630\n",
      "Epoch 227/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5649 - val_loss: 0.5631\n",
      "Epoch 228/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5649 - val_loss: 0.5631\n",
      "Epoch 229/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5649 - val_loss: 0.5630\n",
      "Epoch 230/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5649 - val_loss: 0.5631\n",
      "Epoch 231/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5649 - val_loss: 0.5628\n",
      "Epoch 232/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5649 - val_loss: 0.5631\n",
      "Epoch 233/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5648 - val_loss: 0.5631\n",
      "Epoch 234/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5649 - val_loss: 0.5632\n",
      "Epoch 235/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5649 - val_loss: 0.5630\n",
      "Epoch 236/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5649 - val_loss: 0.5632\n",
      "Epoch 237/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5649 - val_loss: 0.5629\n",
      "Epoch 238/400\n",
      "400/400 [==============================] - 0s 132us/step - loss: 0.5649 - val_loss: 0.5629\n",
      "Epoch 239/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5648 - val_loss: 0.5631\n",
      "Epoch 240/400\n",
      "400/400 [==============================] - 0s 131us/step - loss: 0.5648 - val_loss: 0.5630\n",
      "Epoch 241/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5648 - val_loss: 0.5630\n",
      "Epoch 242/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5648 - val_loss: 0.5631\n",
      "Epoch 243/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5648 - val_loss: 0.5629\n",
      "Epoch 244/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5648 - val_loss: 0.5631\n",
      "Epoch 245/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5648 - val_loss: 0.5630\n",
      "Epoch 246/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5647 - val_loss: 0.5629\n",
      "Epoch 247/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5648 - val_loss: 0.5630\n",
      "Epoch 248/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5647 - val_loss: 0.5631\n",
      "Epoch 249/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5648 - val_loss: 0.5631\n",
      "Epoch 250/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5648 - val_loss: 0.5629\n",
      "Epoch 251/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5647 - val_loss: 0.5631\n",
      "Epoch 252/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5647 - val_loss: 0.5629\n",
      "Epoch 253/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5647 - val_loss: 0.5631\n",
      "Epoch 254/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5647 - val_loss: 0.5629\n",
      "Epoch 255/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5647 - val_loss: 0.5629\n",
      "Epoch 256/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5646 - val_loss: 0.5631\n",
      "Epoch 257/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5647 - val_loss: 0.5629\n",
      "Epoch 258/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5647 - val_loss: 0.5630\n",
      "Epoch 259/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5646 - val_loss: 0.5629\n",
      "Epoch 260/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5646 - val_loss: 0.5629\n",
      "Epoch 261/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5646 - val_loss: 0.5629\n",
      "Epoch 262/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5646 - val_loss: 0.5629\n",
      "Epoch 263/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5646 - val_loss: 0.5630\n",
      "Epoch 264/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5646 - val_loss: 0.5628\n",
      "Epoch 265/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5646 - val_loss: 0.5631\n",
      "Epoch 266/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5646 - val_loss: 0.5628\n",
      "Epoch 267/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 268/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 269/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 270/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 271/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 272/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5646 - val_loss: 0.5630\n",
      "Epoch 273/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5647 - val_loss: 0.5629\n",
      "Epoch 274/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5646 - val_loss: 0.5629\n",
      "Epoch 275/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5646 - val_loss: 0.5630\n",
      "Epoch 276/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5645 - val_loss: 0.5628\n",
      "Epoch 277/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 278/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5646 - val_loss: 0.5630\n",
      "Epoch 279/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5645 - val_loss: 0.5628\n",
      "Epoch 280/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5645 - val_loss: 0.5628\n",
      "Epoch 281/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 282/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5645 - val_loss: 0.5631\n",
      "Epoch 283/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 284/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5645 - val_loss: 0.5628\n",
      "Epoch 285/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5645 - val_loss: 0.5629\n",
      "Epoch 286/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5644 - val_loss: 0.5629\n",
      "Epoch 287/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5644 - val_loss: 0.5630\n",
      "Epoch 288/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 289/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5644 - val_loss: 0.5629\n",
      "Epoch 290/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5644 - val_loss: 0.5628\n",
      "Epoch 291/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 292/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 293/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 294/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5646 - val_loss: 0.5629\n",
      "Epoch 295/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5645 - val_loss: 0.5628\n",
      "Epoch 296/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5644 - val_loss: 0.5629\n",
      "Epoch 297/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5644 - val_loss: 0.5628\n",
      "Epoch 298/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5644 - val_loss: 0.5632\n",
      "Epoch 299/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5645 - val_loss: 0.5630\n",
      "Epoch 300/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5645 - val_loss: 0.5627\n",
      "Epoch 301/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5644 - val_loss: 0.5631\n",
      "Epoch 302/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5644 - val_loss: 0.5627\n",
      "Epoch 303/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5644 - val_loss: 0.5627\n",
      "Epoch 304/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5643 - val_loss: 0.5629\n",
      "Epoch 305/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5643 - val_loss: 0.5630\n",
      "Epoch 306/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5644 - val_loss: 0.5627\n",
      "Epoch 307/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5643 - val_loss: 0.5630\n",
      "Epoch 308/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5643 - val_loss: 0.5628\n",
      "Epoch 309/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5643 - val_loss: 0.5629\n",
      "Epoch 310/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5643 - val_loss: 0.5630\n",
      "Epoch 311/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5643 - val_loss: 0.5630\n",
      "Epoch 312/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5643 - val_loss: 0.5630\n",
      "Epoch 313/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5644 - val_loss: 0.5628\n",
      "Epoch 314/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5643 - val_loss: 0.5627\n",
      "Epoch 315/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5643 - val_loss: 0.5630\n",
      "Epoch 316/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5643 - val_loss: 0.5628\n",
      "Epoch 317/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5643 - val_loss: 0.5628\n",
      "Epoch 318/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5643 - val_loss: 0.5626\n",
      "Epoch 319/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5644 - val_loss: 0.5631\n",
      "Epoch 320/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5643 - val_loss: 0.5628\n",
      "Epoch 321/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5642 - val_loss: 0.5629\n",
      "Epoch 322/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5642 - val_loss: 0.5627\n",
      "Epoch 323/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5642 - val_loss: 0.5629\n",
      "Epoch 324/400\n",
      "400/400 [==============================] - 0s 145us/step - loss: 0.5643 - val_loss: 0.5627\n",
      "Epoch 325/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5642 - val_loss: 0.5630\n",
      "Epoch 326/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5643 - val_loss: 0.5628\n",
      "Epoch 327/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5643 - val_loss: 0.5627\n",
      "Epoch 328/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5642 - val_loss: 0.5632\n",
      "Epoch 329/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5642 - val_loss: 0.5629\n",
      "Epoch 330/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5642 - val_loss: 0.5628\n",
      "Epoch 331/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5642 - val_loss: 0.5626\n",
      "Epoch 332/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5641 - val_loss: 0.5626\n",
      "Epoch 333/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5642 - val_loss: 0.5627\n",
      "Epoch 334/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5641 - val_loss: 0.5628\n",
      "Epoch 335/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5642 - val_loss: 0.5628\n",
      "Epoch 336/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5642 - val_loss: 0.5626\n",
      "Epoch 337/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5642 - val_loss: 0.5630\n",
      "Epoch 338/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5642 - val_loss: 0.5627\n",
      "Epoch 339/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5641 - val_loss: 0.5626\n",
      "Epoch 340/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5642 - val_loss: 0.5625\n",
      "Epoch 341/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5642 - val_loss: 0.5629\n",
      "Epoch 342/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5642 - val_loss: 0.5628\n",
      "Epoch 343/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5641 - val_loss: 0.5627\n",
      "Epoch 344/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5641 - val_loss: 0.5628\n",
      "Epoch 345/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5641 - val_loss: 0.5629\n",
      "Epoch 346/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5641 - val_loss: 0.5626\n",
      "Epoch 347/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5641 - val_loss: 0.5626\n",
      "Epoch 348/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5641 - val_loss: 0.5628\n",
      "Epoch 349/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5641 - val_loss: 0.5627\n",
      "Epoch 350/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5641 - val_loss: 0.5628\n",
      "Epoch 351/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5640 - val_loss: 0.5626\n",
      "Epoch 352/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5640 - val_loss: 0.5626\n",
      "Epoch 353/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5640 - val_loss: 0.5629\n",
      "Epoch 354/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5640 - val_loss: 0.5626\n",
      "Epoch 355/400\n",
      "400/400 [==============================] - 0s 133us/step - loss: 0.5640 - val_loss: 0.5630\n",
      "Epoch 356/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5640 - val_loss: 0.5628\n",
      "Epoch 357/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5640 - val_loss: 0.5626\n",
      "Epoch 358/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5640 - val_loss: 0.5627\n",
      "Epoch 359/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5640 - val_loss: 0.5627\n",
      "Epoch 360/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5640 - val_loss: 0.5627\n",
      "Epoch 361/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5640 - val_loss: 0.5627\n",
      "Epoch 362/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5641 - val_loss: 0.5626\n",
      "Epoch 363/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5640 - val_loss: 0.5626\n",
      "Epoch 364/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5640 - val_loss: 0.5628\n",
      "Epoch 365/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5640 - val_loss: 0.5628\n",
      "Epoch 366/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5640 - val_loss: 0.5628\n",
      "Epoch 367/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5641 - val_loss: 0.5626\n",
      "Epoch 368/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5640 - val_loss: 0.5627\n",
      "Epoch 369/400\n",
      "400/400 [==============================] - 0s 135us/step - loss: 0.5639 - val_loss: 0.5628\n",
      "Epoch 370/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5639 - val_loss: 0.5626\n",
      "Epoch 371/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5639 - val_loss: 0.5626\n",
      "Epoch 372/400\n",
      "400/400 [==============================] - 0s 136us/step - loss: 0.5639 - val_loss: 0.5626\n",
      "Epoch 373/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5640 - val_loss: 0.5627\n",
      "Epoch 374/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5639 - val_loss: 0.5626\n",
      "Epoch 375/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5638 - val_loss: 0.5627\n",
      "Epoch 376/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5639 - val_loss: 0.5628\n",
      "Epoch 377/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5639 - val_loss: 0.5629\n",
      "Epoch 378/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5638 - val_loss: 0.5626\n",
      "Epoch 379/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5639 - val_loss: 0.5625\n",
      "Epoch 380/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5639 - val_loss: 0.5629\n",
      "Epoch 381/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5639 - val_loss: 0.5625\n",
      "Epoch 382/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5639 - val_loss: 0.5626\n",
      "Epoch 383/400\n",
      "400/400 [==============================] - 0s 137us/step - loss: 0.5638 - val_loss: 0.5627\n",
      "Epoch 384/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5638 - val_loss: 0.5625\n",
      "Epoch 385/400\n",
      "400/400 [==============================] - 0s 138us/step - loss: 0.5638 - val_loss: 0.5624\n",
      "Epoch 386/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5638 - val_loss: 0.5626\n",
      "Epoch 387/400\n",
      "400/400 [==============================] - 0s 144us/step - loss: 0.5637 - val_loss: 0.5625\n",
      "Epoch 388/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5638 - val_loss: 0.5629\n",
      "Epoch 389/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5638 - val_loss: 0.5623\n",
      "Epoch 390/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5638 - val_loss: 0.5626\n",
      "Epoch 391/400\n",
      "400/400 [==============================] - 0s 143us/step - loss: 0.5638 - val_loss: 0.5627\n",
      "Epoch 392/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5637 - val_loss: 0.5626\n",
      "Epoch 393/400\n",
      "400/400 [==============================] - 0s 139us/step - loss: 0.5638 - val_loss: 0.5630\n",
      "Epoch 394/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5639 - val_loss: 0.5628\n",
      "Epoch 395/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5639 - val_loss: 0.5625\n",
      "Epoch 396/400\n",
      "400/400 [==============================] - 0s 134us/step - loss: 0.5638 - val_loss: 0.5627\n",
      "Epoch 397/400\n",
      "400/400 [==============================] - 0s 141us/step - loss: 0.5638 - val_loss: 0.5626\n",
      "Epoch 398/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5638 - val_loss: 0.5627\n",
      "Epoch 399/400\n",
      "400/400 [==============================] - 0s 142us/step - loss: 0.5638 - val_loss: 0.5626\n",
      "Epoch 400/400\n",
      "400/400 [==============================] - 0s 140us/step - loss: 0.5638 - val_loss: 0.5627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb38280750>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=400,\n",
    "                batch_size=50,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 16,795\n",
      "Trainable params: 16,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#extract encoder layers from the networks\n",
    "def encoderLayers(input_):\n",
    "    output_=input_\n",
    "    for l in range(len(encoding_dim)):\n",
    "        output_=autoencoder.layers[l](output_)\n",
    "    return output_\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "#encoder_layer = autoencoder.layers[0]\n",
    "encoder = Model(input_layer, (encoderLayers(input_layer)))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the data\n",
    "encoded_x = encoder.predict(x_test)\n",
    "decoded_x = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encoder.predict(np.concatenate((x_train,x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3363421 , -0.        ,  0.78147084, -0.        ,  5.585493  ,\n",
       "         1.2504551 , -0.        , -0.        ,  0.01923567, -0.        ,\n",
       "         1.7564486 ,  4.062417  ,  3.8543825 ,  2.4002512 ,  1.2071981 ],\n",
       "       [ 0.7709331 , -0.        ,  2.8277085 , -0.        ,  3.6389208 ,\n",
       "         1.0418524 , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.8897324 ,  4.085449  ,  4.341785  ,  2.5373921 ,  2.4504175 ],\n",
       "       [-0.        , -0.        ,  4.1625543 , -0.        ,  0.4345499 ,\n",
       "         0.46726698, -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.0089458 ,  3.8056495 ,  1.9283712 ,  5.624664  ,  2.9422386 ],\n",
       "       [-0.        , -0.        ,  4.468466  , -0.        ,  0.5748289 ,\n",
       "         0.2916113 , -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.2474947 ,  3.8932695 ,  1.8872777 ,  6.0076885 ,  3.491469  ],\n",
       "       [-0.        , -0.        ,  4.6276383 , -0.        ,  0.8261027 ,\n",
       "         0.589389  , -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.2309331 ,  4.0586543 ,  1.7592663 ,  5.9782953 ,  3.1617277 ],\n",
       "       [-0.        , -0.        ,  5.0600767 , -0.        ,  2.051957  ,\n",
       "         1.2850132 , -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.1650461 ,  4.4938426 ,  1.8776573 ,  5.509412  ,  2.544362  ],\n",
       "       [-0.        , -0.        ,  3.858876  , -0.        ,  2.960638  ,\n",
       "         1.9357933 , -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.0678543 ,  4.9904118 ,  3.892446  ,  4.008107  ,  2.0464873 ],\n",
       "       [ 0.07385674, -0.        ,  3.350483  , -0.        ,  3.5671597 ,\n",
       "         1.5832462 , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.9021201 ,  4.619142  ,  4.39261   ,  3.080364  ,  2.2441766 ],\n",
       "       [-0.        , -0.        ,  4.255377  , -0.        ,  0.31962022,\n",
       "         0.31187218, -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.1269532 ,  3.8427944 ,  1.9765415 ,  5.910512  ,  3.279158  ],\n",
       "       [-0.        , -0.        ,  4.5488896 , -0.        ,  0.4048901 ,\n",
       "         0.39899078, -0.        , -0.        , -0.        , -0.        ,\n",
       "         1.0871717 ,  3.8936324 ,  1.7605236 ,  5.9993644 ,  3.2458582 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the outcome\n",
    "save('Tapeiexchange2.pkl',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
